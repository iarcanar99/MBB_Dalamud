# translator_gemini.py
import os
from dotenv import load_dotenv
import re
import tkinter as tk
from tkinter import messagebox
import json
import difflib
import time
import logging
from enum import Enum
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from text_corrector import TextCorrector, DialogueType
from dialogue_cache import DialogueCache

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ import EnhancedNameDetector ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
try:
    from enhanced_name_detector import EnhancedNameDetector

    HAS_ENHANCED_DETECTOR = True
except ImportError:
    HAS_ENHANCED_DETECTOR = False

load_dotenv()


class TranslatorGemini:
    def __init__(self, settings=None):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö API Key
            error_msg = "GEMINI_API_KEY not found in .env file"
            logging.error(error_msg)
            messagebox.showerror(
                "API Key Error", f"{error_msg}\nPlease add your API key to .env file"
            )
            raise ValueError(error_msg)

        # Initialize Gemini API
        genai.configure(api_key=self.api_key)

        # Initialize default values first
        self.model_name = "gemini-2.0-flash-lite"
        self.max_tokens = 500
        self.temperature = 0.7
        self.top_p = 0.9
        self.current_role_mode = "rpg_general"

        # ‡πÉ‡∏ä‡πâ settings object ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if settings:
            api_params = settings.get_api_parameters()
            self.model_name = api_params.get("model", self.model_name)
            self.max_tokens = api_params.get("max_tokens", self.max_tokens)
            self.temperature = api_params.get("temperature", self.temperature)
            self.top_p = api_params.get("top_p", self.top_p)
            self.current_role_mode = api_params.get("role_mode", self.current_role_mode)
        else:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ settings ‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
            try:
                with open("settings.json", "r") as f:
                    settings_data = json.load(f)
                    api_params = settings_data.get("api_parameters", {})
                    self.model_name = api_params.get("model", "gemini-2.0-flash-lite")
                    self.max_tokens = api_params.get("max_tokens", 500)
                    self.temperature = api_params.get("temperature", 0.7)
                    self.top_p = api_params.get("top_p", 0.9)
                    self.current_role_mode = api_params.get("role_mode", "rpg_general")
            except (FileNotFoundError, json.JSONDecodeError):
                self.model_name = "gemini-2.0-flash-lite"
                self.max_tokens = 500
                self.temperature = 0.7
                self.top_p = 0.9
                self.current_role_mode = "rpg_general"
                logging.warning("Could not load settings.json, using default values")

        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ safety settings - ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏•‡πá‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏• H-game ‡πÑ‡∏î‡πâ
        self.safety_settings = [
            {
                "category": HarmCategory.HARM_CATEGORY_HARASSMENT,
                "threshold": HarmBlockThreshold.BLOCK_NONE,
            },
            {
                "category": HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                "threshold": HarmBlockThreshold.BLOCK_NONE,
            },
            {
                "category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                "threshold": HarmBlockThreshold.BLOCK_NONE,
            },
            {
                "category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                "threshold": HarmBlockThreshold.BLOCK_NONE,
            },
        ]

        # Initialize Gemini model
        genai_model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config={
                "max_output_tokens": self.max_tokens,
                "temperature": self.temperature,
                "top_p": self.top_p,
            },
            safety_settings=self.safety_settings,
        )
        self.model = genai_model

        self.cache = DialogueCache()
        self.last_translations = {}
        self.character_names_cache = set()
        self.text_corrector = TextCorrector()
        self.load_npc_data()
        self.load_example_translations()

        # Session-based character name cache for consistency
        self.session_character_names = {}  # {original_name: translated_name}
        self.session_speaker_count = 0     # Track session activity
        self.max_session_names = 50        # Prevent memory growth
        self.cache_hits = 0                # Track cache performance
        self.cache_misses = 0              # Track cache performance

        # ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ EnhancedNameDetector ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        self.enhanced_detector = None
        if HAS_ENHANCED_DETECTOR:
            try:
                self.enhanced_detector = EnhancedNameDetector(
                    self.character_names_cache
                )
                logging.info("Initialized EnhancedNameDetector successfully")
            except Exception as e:
                logging.warning(f"Failed to initialize EnhancedNameDetector: {e}")
                self.enhanced_detector = None

    def get_current_parameters(self):
        """Return current translation parameters"""
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini ‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô
        displayed_model = self.model_name
        if self.model_name == "gemini-1.5-pro":
            displayed_model = "gemini-1.5-pro"
        elif self.model_name == "gemini-1.5-flash":
            displayed_model = "gemini-1.5-flash"

        return {
            "model": self.model_name,
            "displayed_model": displayed_model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": self.top_p,
        }

    def load_npc_data(self):
        """Load character data, lore, styles, and specific H-game terms from NPC.json."""
        try:
            with open("NPC.json", "r", encoding="utf-8") as file:
                npc_data = json.load(file)
                self.character_data = npc_data["main_characters"]
                self.context_data = npc_data["lore"]
                self.character_styles = npc_data["character_roles"]

                # ‡πÇ‡∏´‡∏•‡∏î word_fixes ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                if "word_fixes" in npc_data:
                    self.word_fixes = npc_data["word_fixes"]
                    logging.info(
                        f"Loaded {len(self.word_fixes)} word fixes from NPC.json"
                    )
                else:
                    self.word_fixes = {}

                # Update character_names_cache
                self.character_names_cache = set()
                self.character_names_cache.add("???")

                # Load main characters
                for char in self.character_data:
                    self.character_names_cache.add(char["firstName"])
                    if char["lastName"]:
                        self.character_names_cache.add(
                            f"{char['firstName']} {char['lastName']}"
                        )

                # Load NPCs
                for npc in npc_data["npcs"]:
                    self.character_names_cache.add(npc["name"])

                logging.info("TranslatorGemini: Loaded NPC.json successfully")

        except FileNotFoundError:
            raise FileNotFoundError("NPC.json file not found")
        except json.JSONDecodeError:
            raise ValueError("Invalid JSON in NPC.json")

    def load_example_translations(self):
        self.example_translations = {
            "'Tis": "‡∏ä‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô...",
            "'I do": "‡∏â‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à",
            "'do": "‡∏â‡∏±‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à",
            "'Twas": "‡∏°‡∏±‡∏ô‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏õ‡πá‡∏ô...",
            "Nay": "‡∏´‡∏≤‡∏°‡∏¥‡πÑ‡∏î‡πâ",
            "Aye": "‡∏ô‡∏±‡πà‡∏ô‡∏™‡∏¥‡∏ô‡∏∞, ‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏∞, ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô",
            "Mayhaps": "‡∏ö‡∏≤‡∏á‡∏ó‡∏µ...",
            "Hm...": "‡∏≠‡∏∑‡∏°...",
            "Wait!": "‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏Å‡πà‡∏≠‡∏ô!",
            "My friend...": "‡∏™‡∏´‡∏≤‡∏¢‡∏Ç‡πâ‡∏≤...",
            "Tataru?": "Tataru ‡πÄ‡∏´‡∏£‡∏≠?",
            "Estinien!": "Estinien!",
            "sigh": "‡πÄ‡∏Æ‡πà‡∏≠..",
            "Hmph.": "‡∏Æ‡∏∂‡πà‡∏°.",
            # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß
        }

    def update_parameters(
        self, model=None, max_tokens=None, temperature=None, top_p=None, **kwargs
    ):
        """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•"""
        try:
            old_params = {
                "model": self.model_name,
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "top_p": self.top_p,
            }

            changes = []

            if model is not None:
                # --- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ: ‡πÄ‡∏û‡∏¥‡πà‡∏° gemini-2.0-flash ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå ---
                valid_models = [
                    "gemini-1.5-pro",
                    "gemini-1.5-flash",
                    "gemini-2.0-flash-lite",
                    "gemini-2.0-flash",  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
                ]
                # -----------------------------------------------------------
                if model not in valid_models:
                    raise ValueError(
                        f"Invalid model for Gemini translator. Must be one of: {', '.join(valid_models)}"
                    )
                self.model_name = model
                changes.append(f"Model: {old_params['model']} -> {model}")

            if max_tokens is not None:
                if not (100 <= max_tokens <= 2000):  # Gemini supports up to 2048 tokens
                    raise ValueError(
                        f"Max tokens must be between 100 and 2000, got {max_tokens}"
                    )
                self.max_tokens = max_tokens
                changes.append(
                    f"Max tokens: {old_params['max_tokens']} -> {max_tokens}"
                )

            if temperature is not None:
                if not (0.0 <= temperature <= 1.0):  # Gemini uses 0-1 scale
                    raise ValueError(
                        f"Temperature must be between 0.0 and 1.0, got {temperature}"
                    )
                self.temperature = temperature
                changes.append(
                    f"Temperature: {old_params['temperature']} -> {temperature}"
                )

            if top_p is not None:
                if not (0.0 <= top_p <= 1.0):
                    raise ValueError(f"Top P must be between 0.0 and 1.0, got {top_p}")
                self.top_p = top_p
                changes.append(f"Top P: {old_params['top_p']} -> {top_p}")

            # Re-initialize the model with new parameters
            logging.info(
                f"Recreating Gemini model with parameters: {self.model_name}, max_tokens={self.max_tokens}, temp={self.temperature}"
            )
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config={
                    "max_output_tokens": self.max_tokens,
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                },
                safety_settings=self.safety_settings,
            )
            logging.info(f"Successfully recreated Gemini model: {self.model}")

            if changes:
                logging.info("\n=== Gemini Parameters Updated ===")
                for change in changes:
                    logging.info(change)
                logging.info(f"Current model: {self.model_name}")
                logging.info("==========================\n")

            return changes

        except Exception as e:
            error_msg = f"Error updating Gemini parameters: {str(e)}"
            logging.error(error_msg)
            raise ValueError(error_msg)

    def set_role_mode(self, role_mode):
        """Set the current role mode for translation"""
        valid_roles = ["rpg_general", "adult_enhanced"]
        if role_mode in valid_roles:
            self.current_role_mode = role_mode
            logging.info(f"Role mode set to: {role_mode}")
        else:
            logging.warning(
                f"Invalid role mode: {role_mode}, keeping current: {self.current_role_mode}"
            )

    def get_relevant_names(self, text):
        """Extract only character names mentioned in the current text (OPTIMIZATION)"""
        relevant_names = set()
        text_lower = text.lower()

        # Check for names that appear in the text
        for name in self.character_names_cache:
            if name.lower() in text_lower:
                relevant_names.add(name)

        # Always include essential names that might appear frequently
        essential_names = {
            "Y'shtola", "Alphinaud", "Alisaie", "Wuk Lamat", "???",
            "Estinien", "G'raha Tia", "Thancred", "Urianger", "Krile",
            "Emet-Selch", "Hythlodaeus", "Venat", "Meteion", "Zenos",
            "Koana", "Zoraal Ja", "Gulool Ja", "Sphene", "Otis"
        }
        for name in essential_names:
            if name in self.character_names_cache:
                relevant_names.add(name)

        # Limit to maximum 20 names to control token usage (increased for better coverage)
        # Prioritize essential names first, then detected names
        essential_in_relevant = [name for name in essential_names if name in relevant_names]
        other_names = [name for name in relevant_names if name not in essential_names]

        # Combine with essential names first to ensure they're always included
        prioritized_names = essential_in_relevant + other_names
        return prioritized_names[:20]

    def get_relevant_lore_terms(self, text, speaker=None):
        """Extract only lore terms that might be relevant to current text (OPTIMIZATION)"""
        relevant_terms = {}
        text_lower = text.lower()

        # Priority 1: Direct keyword matches
        for term, explanation in self.context_data.items():
            if term.lower() in text_lower:
                relevant_terms[term] = explanation

        # Priority 2: Character-specific lore (if we know the speaker)
        if speaker and len(relevant_terms) < 5:
            character_related_terms = ["Warrior of Light", "Scion", "Crystal", "Eorzea"]
            for term in character_related_terms:
                if term in self.context_data and len(relevant_terms) < 5:
                    relevant_terms[term] = self.context_data[term]

        # Priority 3: Essential game terms (always include if space allows)
        essential_terms = ["Warrior of Light", "Eorzea"]
        for term in essential_terms:
            if (
                term in self.context_data
                and term not in relevant_terms
                and len(relevant_terms) < 3
            ):
                relevant_terms[term] = self.context_data[term]

        return relevant_terms

    def count_tokens_estimate(self, text):
        """Rough token estimation for monitoring (OPTIMIZATION)"""
        # Rough estimate: 1 token ‚âà 4 characters for mixed EN/TH
        return len(text) // 4

    def get_system_prompt(self, role_mode=None):
        """Get system prompt based on current role mode"""
        if role_mode is None:
            role_mode = self.current_role_mode

        if role_mode == "adult_enhanced":
            return self.get_adult_enhanced_prompt()
        else:
            return self.get_rpg_general_prompt()

    def get_rpg_general_prompt(self):
        """Text Hook optimized RPG translation prompt for Final Fantasy XIV"""
        return (
            "You are a professional translator specializing in Final Fantasy XIV text hook localization. "
            "You receive precise, complete game text directly from the game engine with perfect accuracy. "
            "Translate this English text to Thai following these requirements:\n\n"
            "**TEXT HOOK ADVANTAGES:**\n"
            "- Perfect text accuracy\n"
            "- Complete dialogue context\n"
            "- Real-time character identification\n"
            "- Precise message boundaries\n\n"
            "**TRANSLATION REQUIREMENTS:**\n"
            "1. **Complete Translation**: Translate ALL content completely - text hook provides perfect input, expect perfect output\n"
            "2. **Character Fidelity**: Maintain the speaker's tone and personality as described in 'Character's style' section. This is the highest priority.\n"
            "3. **Name Preservation (CRITICAL)**: NEVER translate character names, place names, or special terms from the database. Character names must ALWAYS remain in English exactly as provided, even when mentioned in dialogue. Examples: Y'shtola stays Y'shtola, Estinien stays Estinien, G'raha Tia stays G'raha Tia.\n"
            "4. **Lore Integration**: Use Thai explanations from 'Special terms' section below instead of direct translation\n"
            "5. **Default Tone - Modern Game Dialogue**: The default translation style is modern, natural Thai suitable for a video game script. This means clear, direct language. This style should ONLY be changed if the 'Character's style' explicitly demands an archaic or unique tone.\n"
            "6. **ABSOLUTE PROHIBITION (CRITICAL RULE)**: Under NO circumstances are you to use the following modern polite particles: '‡∏Ñ‡πà‡∏∞', '‡∏Ñ‡∏∞', '‡∏Ñ‡∏£‡∏±‡∏ö', '‡∏î‡∏¥‡∏â‡∏±‡∏ô', '‡∏ô‡∏∞‡∏Ñ‡∏∞', '‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö', '‡∏Ç‡πâ‡∏≤‡∏û‡πÄ‡∏à‡πâ‡∏≤'. Using these words is a critical error that completely destroys the game's atmosphere. If you use '‡∏Ç‡πâ‡∏≤‡∏û‡πÄ‡∏à‡πâ‡∏≤' in any translation, it is an immediate failure. Use appropriate pronouns like '‡∏ä‡∏±‡πâ‡∏ô', '‡∏â‡∏±‡∏ô', '‡∏Ç‡πâ‡∏≤', '‡πÄ‡∏£‡∏≤' instead. Politeness must be conveyed through respectful word choices and sentence structure ONLY, not by adding these particles.\n"
            "7. Pronoun Selection Guidelines (Context and Personality Based):\n"
            "   - For serious conversations about plans/stories/important matters: Use '‡∏Ñ‡∏∏‡∏ì' or '‡πÄ‡∏à‡πâ‡∏≤' instead of '‡πÅ‡∏Å' for appropriateness\n"
            "   - Follow Character's style as main priority:\n"
            "     ‚Ä¢ Characters described as '‡∏™‡∏∏‡∏†‡∏≤‡∏û', '‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•', '‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô' should avoid '‡πÅ‡∏Å', use '‡∏Ñ‡∏∏‡∏ì' or '‡πÄ‡∏à‡πâ‡∏≤'\n"
            "     ‚Ä¢ Characters described as '‡πÄ‡∏ü‡∏µ‡∏¢‡∏™', '‡∏´‡πâ‡∏≤‡∏ß', '‡∏´‡∏±‡∏ß‡∏£‡πâ‡∏≠‡∏ô', '‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏Ç‡∏ß‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ã‡∏≤‡∏Å' can use '‡πÄ‡∏à‡πâ‡∏≤' normally and '‡πÅ‡∏Å' when challenging/arguing\n"
            "     ‚Ä¢ Characters described as '‡∏Å‡πâ‡∏≤‡∏ß‡∏£‡πâ‡∏≤‡∏ß', '‡∏î‡∏∏‡∏î‡∏±‡∏ô', '‡∏´‡∏¢‡∏≤‡∏ö' can use '‡πÅ‡∏Å' or '‡πÄ‡∏≠‡πá‡∏á'\n"
            "   - Consider context appropriateness based on situation and emotional tone\n"
            "8. **Profanity and Emotional Expression (Anime Style)**: Strictly avoid harsh, vulgar pronouns like '‡∏Å‡∏π' and '‡∏°‡∏∂‡∏á'. However, to capture strong emotions accurately, using expressive exclamations or mild curses like '‡πÅ‡∏°‡πà‡∏á', '‡πÄ‡∏ä‡∏µ‡πà‡∏¢!', '‡∏ö‡πâ‡∏≤‡πÄ‡∏≠‡πä‡∏¢!' is PERMITTED, but ONLY if the original English text conveys frustration, anger, or shock. The goal is to achieve a vivid, 'anime-style' localization that is expressive without being overly vulgar.\n"
            "9. **Output Format**: Return ONLY the Thai translation - no English text, explanations, or formatting\n\n"
            f"Protected names (use exactly as written): {', '.join(self.character_names_cache)}\n\n"
            "Special terms (use these Thai explanations):\n"
        )

    def get_adult_enhanced_prompt(self):
        """Adult enhanced translation prompt with explicit content support"""
        return (
            "You are an expert translator specializing in translating adult visual novels and mature content from English to Thai. "
            "Your expertise includes handling explicit sexual content, intimate scenes, and mature themes with accuracy and appropriate language.\n"
            "Translate the following English text into Thai, focusing on these enhanced principles:\n\n"
            "ENHANCED GUIDELINES:\n"
            "1. **Bold & Complete Translation:** Translate ALL content completely and directly. "
            "Do NOT censor, omit, or tone down explicit content. Be bold and straightforward with sexual terminology.\n"
            "2. **Mature Thai Expression:** Use appropriate Thai sexual vocabulary and intimate expressions. "
            "Choose words that convey the right level of explicitness - from sensual to graphic as needed.\n"
            "3. **Emotional Intensity:** Capture the full emotional and physical intensity of intimate scenes. "
            "Use expressive language that conveys desire, passion, pleasure, and other mature emotions accurately.\n"
            "4. **Natural Intimacy:** Translate sexual content to sound natural and appealing in Thai, "
            "not clinical or awkward. Use terms that enhance rather than diminish the erotic atmosphere.\n"
            "5. **Contemporary Thai as a Base**: Translate using natural, easy-to-understand Thai, like dialogue in modern RPGs (e.g., Final Fantasy XVI, Persona 5). The primary goal is natural-sounding conversation. Prioritize the 'Character's style' data; if a character needs to sound archaic or formal, that data will specify it. Otherwise, default to a modern, clear tone.\n"
            "6. **Natural Particles and Pronouns**: To make conversations sound authentic, the use of '‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞' is PERMITTED and encouraged for polite or formal situations, based on the character's personality. Avoid overly archaic or overly casual particles unless specified by the character's style.\n"
            "   - **Still Forbidden**: '‡πÄ‡∏à‡πâ‡∏≤‡∏Ñ‡πà‡∏∞', '‡πÄ‡∏û‡∏Ñ‡∏∞' (too historical); '‡∏à‡πâ‡∏∞', '‡∏Æ‡∏∞' (can be too casual and break immersion).\n"
            "   - Pronouns should be chosen based on context and 'Character's style' for natural interactions, not rigid rules.\n"
            "7. **Output Format**: Return ONLY the Thai translation - no English text, explanations, or formatting\n\n"
            "8. **RPG Fantasy Tone - STRICTLY FORBIDDEN:** Even in adult content, maintain the fantasy RPG atmosphere. DO NOT USE modern casual particles like '‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞/‡∏ô‡∏∞‡∏Ñ‡∏∞/‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö/‡∏î‡∏¥‡∏â‡∏±‡∏ô/‡πÄ‡∏à‡πâ‡∏≤‡∏Ñ‡πà‡∏∞/‡πÄ‡∏û‡∏Ñ‡∏∞/‡∏à‡πâ‡∏∞/‡∏Æ‡∏∞' that would break immersion in a fantasy setting. This is a hard rule.\n"
            "9. **Pure Output:** Return ONLY the Thai translation with full adult content intact.\n\n"
            "Remember: Your role is to provide authentic, unfiltered translations that preserve the full adult nature of the content. "
            "Do not shy away from explicit terminology - embrace it for accurate, engaging translation while maintaining the fantasy RPG setting.\n\n"
        )

    def is_translation_complete(self, original_text, translated_text):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)

        Args:
            original_text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            translated_text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡πÅ‡∏•‡πâ‡∏ß

        Returns:
            bool: True ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå, False ‡∏ñ‡πâ‡∏≤‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        """
        # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        if not original_text or not translated_text:
            return False

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏© - ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏™‡∏°‡∏≠
        if translated_text.strip() in ["???", "Y'shtola", "Yshtola"]:
            return True

        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç 2 ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö ???
        if (
            re.match(r"^2+\??$", original_text.strip())
            or original_text.strip() == "???"
        ):
            return translated_text.strip() == "???"

        # ‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        original_content = original_text
        translated_content = translated_text

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î‡∏≠‡∏≠‡∏Å
        if ":" in original_text:
            parts = original_text.split(":", 1)
            if len(parts) == 2:
                original_content = parts[1].strip()

        if ":" in translated_text:
            parts = translated_text.split(":", 1)
            if len(parts) == 2:
                translated_content = parts[1].strip()

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
        original_words = original_content.split()
        original_char_length = len(original_content)
        translated_words = translated_content.split()
        translated_char_length = len(translated_content)

        # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏Å (1-3 ‡∏Ñ‡∏≥) ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÄ‡∏™‡∏°‡∏≠‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
        if len(original_words) <= 3 and translated_char_length >= 2:
            return True

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ä‡∏∑‡πà‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢ (5 ‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤) ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ
        if len(original_words) <= 5 and translated_char_length >= 5:
            return True

        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ô (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏≥‡πÑ‡∏ó‡∏¢‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏°‡∏≤‡∏Å)
        # ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 1:0.6
        char_ratio = translated_char_length / max(1, original_char_length)

        # ‡∏ñ‡πâ‡∏≤‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 0.3 (30%) ‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        # ‡πÅ‡∏ï‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        if original_char_length > 50 and char_ratio < 0.3:
            return False

        # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô
        if original_char_length <= 50:
            return True

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
        if translated_content.strip().endswith(("-", "...")):
            # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ ... ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ -
            if translated_content.strip().endswith("-"):
                return False
            # ‡∏ñ‡πâ‡∏≤‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ ... ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏ö‡∏î‡πâ‡∏ß‡∏¢ ... ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            if not original_content.strip().endswith("...") and char_ratio < 0.5:
                return False

        # ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
        return True

    def translate(
        self, text, source_lang="English", target_lang="Thai", is_choice_option=False
    ):
        """
        ‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•
            source_lang: ‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (default: English)
            target_lang: ‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (default: Thai)
            is_choice_option: ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (default: False)
        Returns:
            str: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡πÅ‡∏•‡πâ‡∏ß
        """
        try:
            if not text:
                logging.warning("Empty text received for translation")
                return ""

            # ‡πÉ‡∏™‡πà try-except ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ split_speaker_and_content ‡πÄ‡∏Å‡∏¥‡∏î error
            try:
                # ‡πÉ‡∏ä‡πâ text_corrector instance ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
                speaker, content, dialogue_type = (
                    self.text_corrector.split_speaker_and_content(text)
                )
            except (TypeError, ValueError, AttributeError) as e:
                # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà split_speaker_and_content ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ None ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
                logging.warning(
                    f"Error splitting text content: {e}, treating as normal text"
                )
                speaker = None
                content = text
                dialogue_type = None

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö word_fixes ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            if hasattr(self, "word_fixes") and text.strip() in self.word_fixes:
                fixed_text = self.word_fixes[text.strip()]
                if fixed_text == "???":
                    return "???"

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç 2 ‡πÅ‡∏•‡∏∞ ???
            if text.strip() in ["2", "2?", "22", "22?", "222", "222?", "???"]:
                return "???"

            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡∏Ç 2 ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á (2, 22, 222, 2222, ‡∏Ø‡∏•‡∏Ø)
            if re.match(r"^2+\??$", text.strip()):
                return "???"

            # ‡πÉ‡∏ä‡πâ EnhancedNameDetector ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            if self.enhanced_detector:
                try:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    speaker, content, detected_type = (
                        self.enhanced_detector.enhanced_split_speaker_and_content(text)
                    )
                    if detected_type == DialogueType.CHARACTER and speaker == "???":
                        return "???"
                except Exception as e:
                    logging.warning(f"Error using EnhancedNameDetector: {e}")

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if is_choice_option:
                # ‡∏ñ‡πâ‡∏≤ MBB ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô choice ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å translate_choice ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
                logging.info(f"Choice option flag is True, calling translate_choice")
                return self.translate_choice(text)
            else:
                # ‡∏ñ‡πâ‡∏≤ MBB ‡πÑ‡∏°‡πà‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô choice ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                try:
                    is_choice, prompt_part, choices = self.is_similar_to_choice_prompt(
                        text
                    )
                    if is_choice:
                        logging.info(
                            f"Internal choice detection found choice, calling translate_choice"
                        )
                        return self.translate_choice(text)
                except Exception as choice_err:
                    logging.warning(f"Error checking choice prompt: {choice_err}")

            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î
            if dialogue_type == DialogueType.CHARACTER and speaker:
                # ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ???
                if speaker.startswith("?"):
                    speaker = "???"

                # Check session cache for consistent character names (EXACT MATCH ONLY)
                try:
                    # Normalize speaker for lookup - EXACT MATCH ONLY to avoid substring conflicts
                    normalized_speaker = speaker.lower().strip()

                    # CRITICAL: Use exact string match to prevent "Gulool Ja" vs "Gulool Ja Ja" conflicts
                    if normalized_speaker in self.session_character_names:
                        character_name = self.session_character_names[normalized_speaker]
                        self.cache_hits += 1
                        logging.debug(f"[NAME CACHE] Cache HIT: {speaker} -> {character_name}")
                    else:
                        character_name = speaker  # Use original logic if not cached
                        self.cache_misses += 1
                        logging.debug(f"[NAME CACHE] Cache MISS: {speaker} (will translate)")
                except Exception as e:
                    logging.warning(f"Name cache lookup error: {e}, falling back to original logic")
                    character_name = speaker  # Fallback to original behavior
                dialogue = content

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•
                if (
                    dialogue in self.last_translations
                    and character_name == self.cache.get_last_speaker()
                ):
                    translated_dialogue = self.last_translations[dialogue]
                    return f"{character_name}: {translated_dialogue}"

                # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£
                character_info = self.get_character_info(character_name)
                context = ""
                if character_info:
                    context = (
                        f"Character: {character_info['firstName']}, "
                        f"Gender: {character_info['gender']}, "
                        f"Role: {character_info['role']}, "
                        f"Relationship: {character_info['relationship']}"
                    )
                elif character_name == "???":
                    context = "Character: Unknown, Role: Mystery character"

                # 2. ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î
                character_style = self.character_styles.get(character_name, "")
                if not character_style and character_name == "???":
                    character_style = (
                        "‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏á‡∏™‡∏±‡∏¢ ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏û‡∏® ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏≥‡∏™‡∏£‡∏£‡∏û‡∏ô‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡πÄ‡∏û‡∏® "
                        "‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏¥‡∏®‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡∏ü‡∏±‡∏á‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô ‡πÄ‡∏ä‡πà‡∏ô '‡πÄ‡∏£‡∏≤' ‡πÅ‡∏ó‡∏ô '‡∏â‡∏±‡∏ô' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏Ç‡πâ‡∏≤' "
                        "‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏û‡∏π‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏Å‡∏ß‡∏° ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏•‡∏∂‡∏Å‡∏•‡∏±‡∏ö"
                    )

                self.cache.add_speaker(character_name)

            else:
                # ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
                dialogue = text
                character_name = ""
                context = ""
                character_style = ""

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•
            # Use role-specific system prompt
            base_prompt = self.get_system_prompt()
            # OPTIMIZATION: Use smart lore filtering instead of all terms
            relevant_lore_terms = self.get_relevant_lore_terms(dialogue, character_name)

            prompt = (
                base_prompt + f"Context: {context}\n"
                f"Character's style: {character_style}\n"
                f"Preserve names: {', '.join(self.get_relevant_names(dialogue))}\n\n"
                "Special Terms (Strongly prefer using these Thai translations):\n"
            )

            for term, explanation in relevant_lore_terms.items():
                prompt += f"{term}: {explanation}\n"

            prompt += f"\n\nText to translate: {dialogue}"

            # OPTIMIZATION: Monitor token usage
            estimated_tokens = self.count_tokens_estimate(prompt)
            logging.info(
                f"üîç Estimated prompt tokens: {estimated_tokens} (Target: <600)"
            )

            if estimated_tokens > 800:
                logging.warning(
                    f"‚ö†Ô∏è High token usage detected: {estimated_tokens} tokens"
                )
            elif estimated_tokens < 500:
                logging.info(f"‚úÖ Optimized token usage: {estimated_tokens} tokens")

            try:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Content ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini API
                generation_config = {
                    "max_output_tokens": self.max_tokens,
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                }

                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•
                print(
                    f"                                            ", end="\r"
                )  # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                print(f"[Gemini API] Translating: {dialogue[:40]}...", end="\r")

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
                start_time = time.time()

                # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API - ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ prompt (‡πÑ‡∏°‡πà‡∏™‡πà‡∏á dialogue ‡πÅ‡∏¢‡∏Å)
                response = self.model.generate_content(
                    prompt,  # ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ prompt ‡πÄ‡∏ï‡πá‡∏°‡πÜ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á dialogue ‡πÅ‡∏¢‡∏Å
                    generation_config=generation_config,
                    safety_settings=self.safety_settings,
                )

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
                elapsed_time = time.time() - start_time

                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô token ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏à‡∏≤‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥
                input_words = len(prompt.split())
                output_words = (
                    len(response.text.split()) if hasattr(response, "text") else 0
                )
                # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì token ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 1 ‡∏Ñ‡∏≥ = 1.3 token
                input_tokens = int(input_words * 1.3)
                output_tokens = int(output_words * 1.3)
                total_tokens = input_tokens + output_tokens

                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÇ‡∏ã‡∏•
                short_model = (
                    self.model_name if hasattr(self, "model_name") else "gemini"
                )
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
                print(f"[Gemini API] Translation complete                ", end="\r")
                print(
                    f"[{short_model.upper()}] : {dialogue[:30]}... -> ~{total_tokens} tokens ({elapsed_time:.2f}s)"
                )
                logging.info(
                    f"[Gemini API] Estimated tokens: ~{input_tokens} (input) + ~{output_tokens} (output) = ~{total_tokens} tokens in {elapsed_time:.2f}s"
                )

                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å response ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
                if hasattr(response, "text") and response.text:
                    translated_dialogue = response.text.strip()
                else:
                    raise ValueError("No response text from Gemini API")

                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏•
                translated_dialogue = re.sub(
                    r"\b(‡∏Ñ‡∏£‡∏±‡∏ö|‡∏Ñ‡πà‡∏∞|‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞)\b", "", translated_dialogue
                ).strip()
                for term in relevant_lore_terms:
                    translated_dialogue = re.sub(
                        r"\b" + re.escape(term) + r"\b",
                        term,
                        translated_dialogue,
                        flags=re.IGNORECASE,
                    )

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏•‡∏Ç 2 ‡πÅ‡∏•‡∏∞ ???
                if re.match(r"^2+\??$", dialogue.strip()) or dialogue.strip() == "???":
                    translated_dialogue = "???"

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏•‡∏Ç 2 ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
                if dialogue.strip() and re.match(r"^\s*2+\s*$", dialogue.strip()):
                    translated_dialogue = "???"

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                if character_name:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç 2
                    if (
                        re.match(r"^2+$", character_name)
                        or character_name.strip() == "???"
                    ):
                        character_name = "???"
                    final_translation = f"{character_name}: {translated_dialogue}"
                else:
                    final_translation = translated_dialogue

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•
                if not self.is_translation_complete(text, final_translation):
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏ã‡πâ‡∏≥
                    skip_retranslation = False

                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏ã‡πâ‡∏≥
                    if len(text.split()) <= 5:
                        skip_retranslation = True
                        logging.info("Skip retranslation for short text")

                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏ã‡πâ‡∏≥
                    if any(name in text for name in ["Y'shtola", "Yshtola", "???"]):
                        skip_retranslation = True
                        logging.info("Skip retranslation for character names")

                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏û‡∏π‡∏î ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                    if ":" in text and len(text.split(":")[1].strip()) < 30:
                        skip_retranslation = True
                        logging.info("Skip retranslation for short dialogue")

                    if not skip_retranslation:
                        logging.warning(
                            "Translation appears incomplete, retrying with stronger prompt"
                        )

                        # ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢ prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏¢‡πâ‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
                        enhanced_prompt = (
                            prompt
                            + "\n\nVERY IMPORTANT: You MUST translate the ENTIRE text completely. Do not cut off or truncate any part of the message."
                        )

                        retry_response = self.model.generate_content(
                            enhanced_prompt,
                            generation_config=generation_config,
                            safety_settings=self.safety_settings,
                        )

                        if hasattr(retry_response, "text") and retry_response.text:
                            retry_translation = retry_response.text.strip()

                            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏•
                            retry_translation = re.sub(
                                r"\b(‡∏Ñ‡∏£‡∏±‡∏ö|‡∏Ñ‡πà‡∏∞|‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞)\b", "", retry_translation
                            ).strip()

                            # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û - ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡πÉ‡∏´‡∏°‡πà‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏Å‡πÜ ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡πÉ‡∏ä‡πâ
                            if len(retry_translation) > len(translated_dialogue) * 1.3:
                                translated_dialogue = retry_translation

                                if character_name:
                                    final_translation = (
                                        f"{character_name}: {translated_dialogue}"
                                    )
                                else:
                                    final_translation = translated_dialogue

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á cache ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏õ‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
                self.last_translations[dialogue] = translated_dialogue
                if character_name:
                    self.cache.add_validated_name(character_name)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤ cache

                # Store character name in session cache for consistency (EXACT MATCH ONLY)
                try:
                    if speaker and character_name:
                        # Normalize speaker key for better matching - EXACT MATCH ONLY
                        normalized_speaker = speaker.lower().strip()

                        # Only store if translation actually occurred or if it's a new entry
                        # CRITICAL: This prevents substring conflicts by using exact string matches
                        if (normalized_speaker not in self.session_character_names or
                            self.session_character_names[normalized_speaker] != character_name):

                            self.session_character_names[normalized_speaker] = character_name
                            self.session_speaker_count += 1

                            # Memory management - cleanup old entries using FIFO
                            if len(self.session_character_names) > self.max_session_names:
                                # Remove oldest entries (FIFO approach)
                                keys_to_remove = list(self.session_character_names.keys())[:len(self.session_character_names) // 4]
                                for key in keys_to_remove:
                                    del self.session_character_names[key]
                                logging.debug(f"[NAME CACHE] Cleaned {len(keys_to_remove)} old entries")

                            logging.debug(f"[NAME CACHE] Stored: {speaker} -> {character_name} (normalized: {normalized_speaker})")
                except Exception as e:
                    logging.warning(f"Cache storage error: {e}")

                return final_translation

            except Exception as api_error:
                logging.error(f"Gemini API error: {str(api_error)}")
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏≠‡∏µ‡∏Å‡πÅ‡∏ö‡∏ö‡∏´‡∏ô‡∏∂‡πà‡∏á (‡∏Å‡∏£‡∏ì‡∏µ model ‡πÄ‡∏Å‡πà‡∏≤)
                try:
                    response = self.model.generate_content(
                        [{"role": "user", "parts": [prompt]}],
                        generation_config=generation_config,
                        safety_settings=self.safety_settings,
                    )

                    if hasattr(response, "text") and response.text:
                        translated_dialogue = response.text.strip()

                        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏•
                        translated_dialogue = re.sub(
                            r"\b(‡∏Ñ‡∏£‡∏±‡∏ö|‡∏Ñ‡πà‡∏∞|‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞)\b", "", translated_dialogue
                        ).strip()

                        if character_name:
                            return f"{character_name}: {translated_dialogue}"
                        return translated_dialogue
                    else:
                        raise ValueError("No response text from alternative API call")
                except Exception as alt_error:
                    logging.error(f"Alternative API call also failed: {str(alt_error)}")
                    return f"[Error: {str(api_error)}]"

        except Exception as e:
            logging.error(f"Unexpected error in translation: {str(e)}")
            return f"[Error: {str(e)}]"

    def is_similar_to_choice_prompt(self, text, threshold=0.7):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á choice dialogue

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
            threshold: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ

        Returns:
            tuple: (is_choice, prompt_part, choices) ‡∏´‡∏£‡∏∑‡∏≠ (False, None, None) ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà choice
        """
        try:
            # 1. ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö prompts ‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô choice dialogue (‡∏£‡∏ß‡∏° OCR variations)
            choice_prompts = [
                "What will you say?",
                "What will you say",
                "what will you say?",
                "what will you say",
                "What will YOu say?",  # OCR errors
                "What will YOu say",
                "what will you say",
                "whatwill you say?",
                "what willyou say?",
                "what will yousay?",
                "whatwillyou say?",
                "What would you like to ask?",
                "Choose your response.",
                "Select an option.",
                "How would you like to respond?",
                "Select a dialogue option.",
                "‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£?",
                "‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?",
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
            ]

            # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á prompt ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
            clean_text = text.strip()

            # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ prompt ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            for prompt in choice_prompts:
                if clean_text.startswith(prompt) or clean_text.lower().startswith(
                    prompt.lower()
                ):
                    # ‡∏û‡∏ö prompt ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
                    parts = clean_text.split(prompt, 1)
                    if len(parts) == 2:
                        prompt_part = prompt
                        choices_part = parts[1].strip()

                        # ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
                        choices = []

                        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
                        if "\n" in choices_part:
                            lines = [
                                line.strip()
                                for line in choices_part.split("\n")
                                if line.strip()
                            ]
                            if lines:
                                choices = lines

                        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                        if not choices:
                            number_starters = self._extract_choices_by_starters(
                                choices_part, ["1.", "2.", "3.", "4."]
                            )
                            if number_starters:
                                choices = number_starters

                        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏≠‡∏±‡∏Å‡∏©‡∏£
                        if not choices:
                            letter_starters = self._extract_choices_by_starters(
                                choices_part, ["A.", "B.", "C.", "D."]
                            )
                            if letter_starters:
                                choices = letter_starters

                        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4: ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô
                        if not choices and any(
                            mark in choices_part for mark in [".", "!", "?"]
                        ):
                            import re

                            split_by_punct = re.split(r"(?<=[.!?])\s+", choices_part)
                            if len(split_by_punct) > 1:
                                choices = [
                                    choice.strip()
                                    for choice in split_by_punct
                                    if choice.strip()
                                ]

                        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 5: ‡∏ñ‡πâ‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏á prompt
                        if not choices and choices_part:
                            choices = [choices_part]

                        # ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                        if choices:
                            return True, prompt_part, choices
                    else:
                        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ prompt ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏á
                        return True, prompt, []

                # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ prompt ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)
                if prompt in clean_text or prompt.lower() in clean_text.lower():
                    idx = max(clean_text.lower().find(prompt.lower()), 0)
                    if idx < 20:  # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ï‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡πÉ‡∏ô‡∏£‡∏∞‡∏¢‡∏∞ 20 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å)
                        # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á prompt
                        before_prompt = clean_text[:idx].strip()
                        after_prompt = clean_text[idx + len(prompt) :].strip()

                        # ‡∏ñ‡πâ‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô prompt ‡∏°‡∏µ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 10 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á prompt ‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
                        if len(before_prompt) < 10 and after_prompt:
                            # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
                            choices = []

                            # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                            if "\n" in after_prompt:
                                lines = [
                                    line.strip()
                                    for line in after_prompt.split("\n")
                                    if line.strip()
                                ]
                                if lines:
                                    choices = lines

                            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏á prompt
                            if not choices:
                                choices = [after_prompt]

                            return True, prompt, choices

            # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å OCR ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
            ocr_variants = [
                "Whatwill you say?",
                "What willyou say?",
                "WhatwilI you say?",
                "What wiIl you say?",
                "Vhat will you say?",
                "VVhat will you say?",
            ]

            for variant in ocr_variants:
                if variant in clean_text or variant.lower() in clean_text.lower():
                    # ‡∏û‡∏ö variant ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô "What will you say?"
                    standard_prompt = "What will you say?"
                    idx = max(clean_text.lower().find(variant.lower()), 0)
                    after_variant = clean_text[idx + len(variant) :].strip()

                    # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
                    choices = []

                    # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                    if "\n" in after_variant:
                        lines = [
                            line.strip()
                            for line in after_variant.split("\n")
                            if line.strip()
                        ]
                        if lines:
                            choices = lines

                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏á variant
                    if not choices:
                        choices = [after_variant]

                    return True, standard_prompt, choices

            # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà choice dialogue
            return False, None, None

        except Exception as e:
            logging.warning(f"Error in is_similar_to_choice_prompt: {str(e)}")
            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡∏¥‡∏î error ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
            return False, None, None

    def _extract_choices_by_starters(self, text, starters):
        """‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î

        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
            starters: list ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ["1.", "2."]

        Returns:
            list: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ
        """
        try:
            choices = []

            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            if not text:
                return []

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            found_starter = False
            for starter in starters:
                if starter in text:
                    found_starter = True
                    break

            if not found_starter:
                return []

            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ regex ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
            import re

            pattern = "|".join(re.escape(starter) for starter in starters)
            regex = rf"({pattern})\s*(.*?)(?=(?:{pattern})|$)"

            matches = re.findall(regex, text, re.DOTALL)
            if matches:
                for match in matches:
                    starter, choice_text = match
                    if choice_text.strip():
                        choices.append(f"{starter} {choice_text.strip()}")
                return choices

            # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏ñ‡πâ‡∏≤ regex ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏¢‡∏Å‡πÅ‡∏ö‡∏ö‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°
            remaining_text = text
            current_choice = ""
            current_starter = None

            for i, starter in enumerate(starters):
                if starter in remaining_text:
                    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ starter ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏à‡∏≠ starter ‡πÉ‡∏´‡∏°‡πà
                    if current_starter:
                        # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                        if current_choice:
                            choices.append(
                                f"{current_starter} {current_choice.strip()}"
                            )

                    # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà starter
                    parts = remaining_text.split(starter, 1)
                    remaining_text = parts[1] if len(parts) > 1 else ""
                    current_starter = starter
                    current_choice = remaining_text

                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö starter ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                    next_starter_pos = float("inf")
                    for next_starter in starters[i + 1 :]:
                        pos = remaining_text.find(next_starter)
                        if pos != -1 and pos < next_starter_pos:
                            next_starter_pos = pos

                    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ starter ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                    if next_starter_pos != float("inf"):
                        current_choice = remaining_text[:next_starter_pos]
                        remaining_text = remaining_text[next_starter_pos:]

                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                    if current_choice:
                        choices.append(f"{current_starter} {current_choice.strip()}")

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
            if (
                current_starter
                and current_choice
                and not any(starter in current_choice for starter in starters)
            ):
                choices.append(f"{current_starter} {current_choice.strip()}")

            return choices

        except Exception as e:
            logging.warning(f"Error extracting choices by starters: {str(e)}")
            return []

    def translate_choice(self, text):
        """‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö H-game (‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏• Choices ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)"""
        try:
            # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
            is_choice, header, choices_raw_list = self.is_similar_to_choice_prompt(text)

            if not is_choice or not header:
                logging.warning(
                    f"translate_choice: Not a recognized choice format: {text[:50]}..."
                )
                # Fallback ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà recurse - ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å translate ‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥
                return self.translate(text, is_choice_option=False)

            # 2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î header ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
            translated_header = "‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?"  # Default header for choice prompts
            # (‡∏≠‡∏≤‡∏à‡πÄ‡∏û‡∏¥‡πà‡∏° Logic ‡πÅ‡∏õ‡∏• Header ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)

            # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° choices_text (‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
            # ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å text ‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏° ‡∏´‡∏•‡∏±‡∏á header
            header_len = len(header)
            choices_text = text[
                header_len:
            ].strip()  # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á header ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤

            if not choices_text:  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏£‡∏¥‡∏á‡πÜ
                logging.warning(
                    f"Choice detected but no options found after header: '{header}'"
                )
                return translated_header

            logging.debug(
                f"Header: '{header}', Choices Text Block: '{choices_text[:50]}...'"
            )

            # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ newlines (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ OCR ‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
            if "\n" not in choices_text:
                # ‡∏•‡∏≠‡∏á‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ï‡∏≤‡∏° punctuation
                import re

                # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° ! ? . ‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÉ‡∏´‡∏ç‡πà
                sentence_splits = re.split(r"([.!?])\s+(?=[A-Z])", choices_text)
                if len(sentence_splits) > 1:
                    # ‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Å‡∏•‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
                    sentences = []
                    for i in range(0, len(sentence_splits), 2):
                        if i < len(sentence_splits):
                            sentence = sentence_splits[i]
                            if i + 1 < len(sentence_splits):
                                sentence += sentence_splits[
                                    i + 1
                                ]  # ‡πÄ‡∏û‡∏¥‡πà‡∏° punctuation ‡∏Å‡∏•‡∏±‡∏ö
                            sentences.append(sentence.strip())

                    if len(sentences) > 1:
                        choices_text = "\n".join(sentences)
                        logging.info(
                            f"Auto-separated choices into {len(sentences)} sentences"
                        )

            # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏• Choices ‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô
            try:
                choices_block_prompt = (
                    "You are translating game dialogue choices from English to Thai. "
                    "Translate the following block of text containing ONLY the choice options, preserving the meaning and tone of each option. "
                    "Each line represents a separate dialogue choice option. "
                    "DO NOT add any extra information, context, questions like 'What will you say?', or bullet points.\n\n"
                    f'CHOICE OPTIONS BLOCK:\n"""\n{choices_text}\n"""\n\n'
                    "RULES:\n"
                    "1. Translate EACH choice option on its own line.\n"
                    "2. Each line should be a separate, complete choice.\n"
                    "3. Keep translations concise and natural for game choices.\n"
                    "4. Preserve proper names.\n"
                    "5. Return ONLY the Thai translations, one per line.\n"
                )

                # ‡πÉ‡∏ä‡πâ Generation Config ‡πÄ‡∏î‡∏¥‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
                choice_gen_config = {
                    "max_output_tokens": self.max_tokens,  # ‡πÉ‡∏´‡πâ token ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                    "temperature": max(0.2, self.temperature - 0.2),  # ‡∏•‡∏î temp ‡∏•‡∏á‡∏≠‡∏µ‡∏Å‡∏ô‡∏¥‡∏î
                    "top_p": self.top_p,
                }

                logging.debug("Sending choices block to Gemini for translation...")
                choice_response = self.model.generate_content(
                    choices_block_prompt,
                    generation_config=choice_gen_config,
                    safety_settings=self.safety_settings,
                )

                if hasattr(choice_response, "text") and choice_response.text:
                    translated_choices_block = choice_response.text.strip()
                    logging.debug(
                        f"Raw translated choices block: '{translated_choices_block}'"
                    )

                    # 5. ‡∏ô‡∏≥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏°‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
                    # ‡πÅ‡∏¢‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                    translated_lines = [
                        line.strip()
                        for line in translated_choices_block.split("\n")
                        if line.strip()
                    ]

                    translated_choices_final = []
                    for line in translated_lines:
                        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ AI ‡∏¢‡∏±‡∏á‡πÉ‡∏™‡πà prefix ‡∏°‡∏≤)
                        patterns_to_remove_prefix = [
                            r"^(‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\??[:Ôºö]?)\s*",
                            r"^(What will you say\??[:Ôºö]?)\s*",
                            r"^[‚Ä¢\-*‚ó¶]\s*",  # ‡∏•‡∏ö bullet point ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ï‡∏¥‡∏î‡∏°‡∏≤
                        ]
                        cleaned_line = line
                        for pattern in patterns_to_remove_prefix:
                            cleaned_line = re.sub(
                                pattern, "", cleaned_line, count=1, flags=re.IGNORECASE
                            ).strip()

                        # ‡πÄ‡∏û‡∏¥‡πà‡∏° bullet point
                        if cleaned_line:
                            translated_choices_final.append("‚Ä¢ " + cleaned_line)

                    if translated_choices_final:
                        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ (‡∏ï‡∏≤‡∏° V9 approach)
                        result = f"{translated_header}\n" + "\n".join(
                            translated_choices_final
                        )
                        logging.debug(f"Final Choice translation result:\n{result}")
                        return result
                    else:
                        # ‡∏ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡πÅ‡∏•‡∏∞ clean ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏•‡∏¢
                        logging.warning(
                            "Translated choices block resulted in empty options."
                        )
                        return translated_header  # ‡∏Ñ‡∏∑‡∏ô‡πÅ‡∏Ñ‡πà header

                else:
                    logging.warning(f"Failed to translate choices block.")
                    # Fallback: ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏•)
                    logging.warning("Falling back to translating choices individually.")
                    translated_choices = []
                    for choice in choices_raw_list:  # ‡πÉ‡∏ä‡πâ choices_raw_list ‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡πÑ‡∏ß‡πâ‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å
                        choice = choice.strip()
                        if not choice:
                            continue
                        try:
                            # ‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏î‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
                            choice_prompt_individual = (
                                "You are translating ONLY a single game dialogue choice OPTION provided below from English to Thai. "
                                "Translate ONLY this specific option concisely and naturally.\n\n"
                                f'OPTION TO TRANSLATE: "{choice}"\n\n'
                                "Rules:\n"
                                "1. Translate ONLY the option text provided above.\n"
                                "2. DO NOT include the question or context like 'What will you say?' or '\u0e04\u0e38\u0e13\u0e08\u0e30\u0e1e\u0e39\u0e14\u0e27\u0e48\u0e32\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e44\u0e23?'.\n"
                                "3. Keep the translation concise.\n"
                                "4. Preserve proper names exactly.\n"
                                "5. Return ONLY the Thai translation of the option.\n"
                            )
                            choice_response_fb = self.model.generate_content(
                                choice_prompt_individual
                            )
                            if (
                                hasattr(choice_response_fb, "text")
                                and choice_response_fb.text
                            ):
                                tc = choice_response_fb.text.strip()
                                # Clean fallback result
                                for pattern in [
                                    r"^(‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\??[:Ôºö]?)\s*",
                                    r"^[‚Ä¢\-*‚ó¶]\s*",
                                ]:
                                    tc = re.sub(
                                        pattern, "", tc, count=1, flags=re.IGNORECASE
                                    ).strip()
                                if tc:
                                    translated_choices.append("‚Ä¢ " + tc)
                                else:
                                    translated_choices.append(
                                        f"‚Ä¢ {choice} [NC/FB]"
                                    )  # Fallback Clean failed
                            else:
                                translated_choices.append(
                                    f"‚Ä¢ {choice} [NT/FB]"
                                )  # Fallback Translate failed
                        except Exception as fb_err:
                            logging.error(
                                f"Error during fallback choice translation for '{choice}': {fb_err}"
                            )
                            translated_choices.append(f"‚Ä¢ {choice} [ERR/FB]")

                    if translated_choices:
                        result = f"{translated_header}\n" + "\n".join(
                            translated_choices
                        )
                        return result
                    else:
                        return translated_header  # ‡∏ñ‡πâ‡∏≤ fallback ‡∏Å‡πá‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ

            except Exception as translate_block_error:
                logging.error(
                    f"Error translating choices block: {translate_block_error}"
                )
                # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏≠‡∏≤‡∏à‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ Error ‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏≠‡∏á Fallback ‡πÅ‡∏õ‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡∏≠‡∏±‡∏ô
                return f"[Error translating choices: {translate_block_error}]"

        except Exception as e:
            logging.error(f"General error in translate_choice: {str(e)}")
            import traceback

            logging.error(traceback.format_exc())
            return f"[Error: {str(e)}]"

    def get_character_info(self, character_name):
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ??? ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏•‡∏Ç 2
        if character_name in ["???", "2", "22", "222"] or re.match(
            r"^2+$", character_name
        ):
            return {
                "firstName": "???",
                "gender": "unknown",
                "role": "Mystery character",
                "relationship": "Unknown/Mysterious",
                "pronouns": {"subject": "‡∏â‡∏±‡∏ô", "object": "‡∏â‡∏±‡∏ô", "possessive": "‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô"},
            }

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢ EnhancedNameDetector
        if self.enhanced_detector:
            try:
                # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ ??? ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏õ‡πá‡∏ô ???
                if re.match(r"^[2\?]+\??$", character_name):
                    return {
                        "firstName": "???",
                        "gender": "unknown",
                        "role": "Mystery character",
                        "relationship": "Unknown/Mysterious",
                        "pronouns": {
                            "subject": "‡∏â‡∏±‡∏ô",
                            "object": "‡∏â‡∏±‡∏ô",
                            "possessive": "‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô",
                        },
                    }
            except Exception as e:
                logging.warning(f"Error in enhanced checking for character name: {e}")

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥
        for char in self.character_data:
            if (
                character_name == char["firstName"]
                or character_name == f"{char['firstName']} {char['lastName']}".strip()
            ):
                return char
        return None

    def batch_translate(self, texts, batch_size=10):
        """‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î"""
        translated_texts = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i : i + batch_size]
            translated_batch = [self.translate(text) for text in batch]
            translated_texts.extend(translated_batch)
        return translated_texts

    def analyze_translation_quality(self, original_text, translated_text):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•"""
        # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API
        prompt = (
            "As a translation quality assessor, evaluate the following translation from English to Thai. "
            "Consider factors such as accuracy, naturalness, and preservation of the original tone and style. "
            f"Original (English): {original_text}\n"
            f"Translation (Thai): {translated_text}\n"
            "Provide a brief assessment and a score out of 10."
        )

        try:
            # ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á Gemini API
            response = self.model.generate_content(
                [{"role": "user", "parts": [prompt]}]
            )
            return response.text.strip()
        except Exception as e:
            logging.error(f"Error in translation quality analysis: {str(e)}")
            return "Unable to assess translation quality due to an error."

    def reload_data(self):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏•‡πâ‡∏≤‡∏á cache"""
        print("TranslatorGemini: Reloading NPC data...")
        self.load_npc_data()
        self.load_example_translations()
        self.cache.clear_session()
        self.last_translations.clear()
        print("TranslatorGemini: Data reloaded successfully")

    def analyze_custom_prompt(self, prompt_with_text):
        """Process a custom prompt with AI"""
        try:
            # ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ API
            response = self.model.generate_content(
                [{"role": "user", "parts": [prompt_with_text]}],
                generation_config={
                    "max_output_tokens": self.max_tokens * 2,
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                },
            )
            return response.text.strip()

        except Exception as e:
            logging.error(f"Error in custom prompt analysis: {e}")
            raise ValueError(f"Failed to process text with AI: {str(e)}")


    def get_name_cache_stats(self):
        """Return cache statistics for monitoring character name consistency"""
        total_requests = self.cache_hits + self.cache_misses
        hit_ratio = (self.cache_hits / total_requests * 100) if total_requests > 0 else 0

        return {
            "cached_names": len(self.session_character_names),
            "session_speakers": self.session_speaker_count,
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "hit_ratio_percent": round(hit_ratio, 2),
            "memory_usage_kb": len(str(self.session_character_names)) // 1024,
            "cache_entries": list(self.session_character_names.items())[:5] if self.session_character_names else []
        }
